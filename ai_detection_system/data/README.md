# ğŸ—‚ï¸ AIä»£ç æ£€æµ‹è®­ç»ƒæ•°æ®é›†

è¿™ä¸ªç›®å½•åŒ…å«ç”¨äºè®­ç»ƒAIä»£ç æ£€æµ‹æ¨¡å‹çš„æ•°æ®é›†ï¼Œä¸“é—¨ç”¨äºåŒºåˆ†äººç±»ç¼–å†™çš„ä»£ç å’ŒAIç”Ÿæˆçš„ä»£ç ã€‚

## ğŸ“ æ•°æ®é›†ç»“æ„

```
data/
â”œâ”€â”€ README.md                    # æœ¬æ–‡ä»¶
â”œâ”€â”€ dataset_labels.json          # æ•°æ®é›†æ ‡æ³¨æ–‡ä»¶
â”œâ”€â”€ dataset_loader.py           # æ•°æ®é›†åŠ è½½å™¨
â”œâ”€â”€ human_code_samples.py       # äººç±»ä»£ç æ ·æœ¬
â”œâ”€â”€ ai_code_samples.py          # AIç”Ÿæˆä»£ç æ ·æœ¬
â””â”€â”€ mixed_code_samples.py       # æ··åˆä»£ç æ ·æœ¬
```

## ğŸ“Š æ•°æ®é›†æ¦‚è§ˆ

- **æ€»æ ·æœ¬æ•°**: ~450è¡Œä»£ç 
- **äººç±»ä»£ç **: ~180è¡Œ (40%)
- **AIä»£ç **: ~270è¡Œ (60%)
- **æ–‡ä»¶æ•°**: 3ä¸ªPythonæ–‡ä»¶
- **æ ‡æ³¨è´¨é‡**: æ‰‹å·¥æ ‡æ³¨ + å¯å‘å¼è§„åˆ™

## ğŸ“„ æ–‡ä»¶è¯´æ˜

### 1. human_code_samples.py
**ç‰¹ç‚¹**: äººç±»çœŸå®ç¼–ç¨‹é£æ ¼
- ç®€æ´ç›´æ¥çš„å‡½æ•°å®šä¹‰
- æœ€å°‘å¿…è¦çš„æ³¨é‡Š
- åŸºç¡€é”™è¯¯å¤„ç†
- å®ç”¨çš„å˜é‡å‘½å
- è¾ƒå°‘çš„ç±»å‹æ³¨è§£
- å®é™…å·¥ä½œä»£ç æ¨¡å¼

**ç¤ºä¾‹**:
```python
def add(a, b):
    return a + b

for num in numbers:
    if num % 2 == 0:
        print(num)
```

### 2. ai_code_samples.py
**ç‰¹ç‚¹**: AIç”Ÿæˆä»£ç ç‰¹å¾
- è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²
- å…¨é¢çš„ç±»å‹æ³¨è§£
- å¤æ‚çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—
- æŠ½è±¡åŸºç±»å’Œè®¾è®¡æ¨¡å¼
- è¯¦ç»†çš„å‚æ•°æ–‡æ¡£
- å¤æ‚çš„ç±»å±‚æ¬¡ç»“æ„

**ç¤ºä¾‹**:
```python
class AdvancedDataProcessor(DataProcessorInterface):
    """
    Advanced data processor with comprehensive functionality.
    
    This class implements sophisticated data processing algorithms
    with support for asynchronous operations, error handling,
    and detailed logging capabilities.
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialize the data processor with configuration parameters.
        
        Args:
            config: Configuration dictionary containing processing parameters
        """
```

### 3. mixed_code_samples.py
**ç‰¹ç‚¹**: æ··åˆç¼–ç¨‹é£æ ¼
- åŒ…å«äººç±»å’ŒAIé£æ ¼çš„ä»£ç æ®µ
- ç”¨äºæµ‹è¯•æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›
- çœŸå®é¡¹ç›®ä¸­çš„ä»£ç æ··åˆæƒ…å†µ

## ğŸ·ï¸ æ ‡æ³¨ç³»ç»Ÿ

### dataset_labels.json
åŒ…å«æ¯è¡Œä»£ç çš„è¯¦ç»†æ ‡æ³¨ï¼š
```json
{
  "line_number": {
    "content": "ä»£ç å†…å®¹",
    "is_ai": true/false,
    "confidence": 0.0-1.0
  }
}
```

### ç½®ä¿¡åº¦è¯„åˆ†
- **0.9-1.0**: éå¸¸ç¡®ä¿¡ - æ˜ç¡®çš„AIæˆ–äººç±»æ¨¡å¼
- **0.8-0.9**: ç¡®ä¿¡ - å¼ºæŒ‡æ ‡å­˜åœ¨
- **0.7-0.8**: ä¸­ç­‰ç½®ä¿¡åº¦ - ä¸€äº›æŒ‡æ ‡
- **0.6-0.7**: ä½ç½®ä¿¡åº¦ - æ¨¡ç³Šæ¨¡å¼
- **0.5-0.6**: å¾ˆä½ç½®ä¿¡åº¦ - ä¸æ¸…æ¥š

## ğŸ” AIæ£€æµ‹ç‰¹å¾

### äººç±»ä»£ç ç‰¹å¾
- âœ… ç®€å•ç›´æ¥çš„å‡½æ•°å®šä¹‰
- âœ… æœ€å°‘å¿…è¦çš„æ³¨é‡Š
- âœ… åŸºç¡€é”™è¯¯å¤„ç†
- âœ… ç›´è§‚çš„å˜é‡å
- âœ… è¾ƒå°‘çš„ç±»å‹æ³¨è§£
- âœ… å®ç”¨çš„å·¥ä½œä»£ç æ¨¡å¼

### AIä»£ç ç‰¹å¾
- ğŸ¤– è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²å’Œæè¿°
- ğŸ¤– å¹¿æ³›çš„ç±»å‹æ³¨è§£
- ğŸ¤– å¤æ‚çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—
- ğŸ¤– æŠ½è±¡åŸºç±»å’Œè®¾è®¡æ¨¡å¼
- ğŸ¤– è¯¦ç»†çš„å‚æ•°æ–‡æ¡£
- ğŸ¤– å¤æ‚çš„ç±»å±‚æ¬¡ç»“æ„
- ğŸ¤– å…¨é¢çš„é…ç½®ç³»ç»Ÿ

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. åŠ è½½æ•°æ®é›†
```python
from dataset_loader import CodeDatasetLoader

# åˆå§‹åŒ–åŠ è½½å™¨
loader = CodeDatasetLoader()

# åŠ è½½æ‰€æœ‰æ ·æœ¬
all_samples = loader.load_all_samples()

# è·å–å¹³è¡¡æ•°æ®é›†
human_samples, ai_samples = loader.get_balanced_dataset()

# è·å–è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
train_samples, test_samples = loader.get_training_data(test_split=0.2)
```

### 2. æ•°æ®é›†ç»Ÿè®¡
```python
# è·å–ç»Ÿè®¡ä¿¡æ¯
stats = loader.get_dataset_statistics()
print(f"Total samples: {stats['total_samples']}")
print(f"Human: {stats['human_samples']}, AI: {stats['ai_samples']}")
```

### 3. å¯¼å‡ºè®­ç»ƒæ•°æ®
```python
# å¯¼å‡ºä¸ºJSONæ ¼å¼
export_data = loader.export_training_data("training_data.json")
```

### 4. è¿è¡Œæ¼”ç¤º
```bash
python dataset_loader.py
```

## ğŸ“ˆ æ•°æ®è´¨é‡

### æ ‡æ³¨è´¨é‡ä¿è¯
- **æ‰‹å·¥æ ‡æ³¨**: å…³é”®è¡Œè¿›è¡Œäººå·¥æ ‡æ³¨
- **å¯å‘å¼è§„åˆ™**: åŸºäºAIä»£ç ç‰¹å¾çš„è‡ªåŠ¨æ ‡æ³¨
- **äº¤å‰éªŒè¯**: å¤šç§æ–¹æ³•éªŒè¯æ ‡æ³¨å‡†ç¡®æ€§
- **ç½®ä¿¡åº¦è¯„åˆ†**: æ¯ä¸ªæ ‡æ³¨éƒ½æœ‰ç½®ä¿¡åº¦åˆ†æ•°

### æ•°æ®å¹³è¡¡
- æ”¯æŒè‡ªåŠ¨æ•°æ®å¹³è¡¡
- å¯é…ç½®æ¯ç±»æœ€å¤§æ ·æœ¬æ•°
- è®­ç»ƒ/æµ‹è¯•é›†è‡ªåŠ¨åˆ†å‰²
- éšæœºæ‰“ä¹±ç¡®ä¿å…¬å¹³æ€§

## ğŸ”§ æ‰©å±•æ•°æ®é›†

### æ·»åŠ æ–°æ ·æœ¬
1. åœ¨ç›¸åº”çš„.pyæ–‡ä»¶ä¸­æ·»åŠ ä»£ç 
2. åœ¨dataset_labels.jsonä¸­æ·»åŠ æ ‡æ³¨
3. è¿è¡Œdataset_loader.pyéªŒè¯

### æ·»åŠ æ–°æ–‡ä»¶
1. åˆ›å»ºæ–°çš„.pyæ–‡ä»¶
2. åœ¨dataset_loader.pyä¸­æ·»åŠ æ–‡ä»¶å
3. åœ¨dataset_labels.jsonä¸­æ·»åŠ æ–‡ä»¶ä¿¡æ¯

## ğŸ“Š æ•°æ®é›†ç»Ÿè®¡ç¤ºä¾‹

è¿è¡Œ`python dataset_loader.py`å¯ä»¥çœ‹åˆ°ï¼š

```
ğŸ—‚ï¸  AI Code Detection Dataset Loader Demo
==================================================
ğŸ“Š Dataset Statistics:
  Total samples: 312
  Human samples: 125 (40.1%)
  AI samples: 187 (59.9%)
  Average confidence: 0.823

ğŸ“ File Statistics:
  human_code_samples.py: 89 total (89 human, 0 AI)
  ai_code_samples.py: 156 total (0 human, 156 AI)
  mixed_code_samples.py: 67 total (36 human, 31 AI)

âš–ï¸  Balanced Dataset: 50 human, 50 AI
ğŸš‚ Training Data: 80 train, 20 test
ğŸ’¾ Exported training data with 80 training samples
```

## ğŸ¯ è®­ç»ƒå»ºè®®

### æ•°æ®é¢„å¤„ç†
- ä½¿ç”¨å¹³è¡¡æ•°æ®é›†é¿å…ç±»åˆ«åå·®
- é€‚å½“çš„è®­ç»ƒ/æµ‹è¯•åˆ†å‰²æ¯”ä¾‹
- è€ƒè™‘ç½®ä¿¡åº¦æƒé‡

### æ¨¡å‹è®­ç»ƒ
- ä½¿ç”¨CodeBERTä½œä¸ºåŸºç¡€æ¨¡å‹
- ç»“åˆæ‰‹å·¥ç‰¹å¾å’Œæ·±åº¦ç‰¹å¾
- æ³¨æ„è¿‡æ‹Ÿåˆé—®é¢˜

### è¯„ä¼°æŒ‡æ ‡
- å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°
- æ··æ·†çŸ©é˜µåˆ†æ
- ä¸åŒç½®ä¿¡åº¦é˜ˆå€¼çš„æ€§èƒ½

---

**æ³¨æ„**: è¿™ä¸ªæ•°æ®é›†æ˜¯ä¸ºæ¼”ç¤ºå’Œç ”ç©¶ç›®çš„åˆ›å»ºçš„ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå»ºè®®ä½¿ç”¨æ›´å¤§è§„æ¨¡å’Œæ›´å¤šæ ·åŒ–çš„æ•°æ®é›†ã€‚ 