# 增强版AI代码检测系统架构说明

## 系统概述

增强版AI代码检测系统是一个基于深度学习的代码分析工具，能够逐行检测代码是否由AI生成。系统采用多层次特征融合架构，结合CodeBERT预训练模型和手工特征工程，实现高精度的AI代码识别。

## 架构流程图

```
代码文件/文件夹
       ↓
   文件解析器
       ↓
   ┌─────────────┐
   │ 文件级特征提取 │
   └─────────────┘
       ↓
   ┌─────────────┐
   │ 行级特征提取  │
   └─────────────┘
       ↓
   ┌─────────────┐
   │   特征融合   │
   └─────────────┘
       ↓
   ┌─────────────┐
   │ 行间关系建模  │
   └─────────────┘
       ↓
   ┌─────────────┐
   │ CodeBERT编码 │
   └─────────────┘
       ↓
   ┌─────────────┐
   │   行分类器   │
   └─────────────┘
       ↓
   ┌─────────────┐
   │   预测概率   │
   └─────────────┘
       ↓
   ┌─────────────┐
   │   阈值过滤   │
   └─────────────┘
       ↓
   ┌─────────────┐
   │ AI生成/人工编码 │
   └─────────────┘
       ↓
   ┌─────────────┐
   │   结果聚合   │
   └─────────────┘
       ↓
   ┌─────────────┐
   │   输出系统   │
   └─────────────┘
       ↓
   JSON结果 & API响应
```

## 核心模块详解

### 1. 文件解析器 (FileParser)

**功能**: 解析代码文件并提取基础结构信息

**支持语言**:
- Python (.py)
- Java (.java)
- JavaScript/TypeScript (.js, .jsx, .ts, .tsx)
- C/C++ (.c, .cpp, .cc, .cxx, .h, .hpp, .hxx)
- Go (.go)
- Rust (.rs)
- Ruby (.rb)
- PHP (.php)
- Swift (.swift)
- Kotlin (.kt)

**输出信息**:
```python
{
    'filepath': str,           # 文件路径
    'filename': str,           # 文件名
    'extension': str,          # 文件扩展名
    'total_lines': int,        # 总行数
    'lines': [                 # 逐行信息
        {
            'line_number': int,    # 行号
            'content': str,        # 行内容
            'is_empty': bool,      # 是否空行
            'indent_level': int    # 缩进级别
        }
    ],
    'success': bool            # 解析是否成功
}
```

### 2. 行级特征提取器 (LineFeatureExtractor)

**功能**: 提取每行代码的特征向量 (19维)

**特征类别**:

#### 基础特征 (4维)
- 归一化长度: `min(length / 100.0, 1.0)`
- 归一化缩进: `min(indent_level / 20.0, 1.0)`
- 相对位置: `line_number / total_lines`
- 词汇数量: `min(word_count / 20.0, 1.0)`

#### 内容特征 (4维)
- 注释标识: `bool(has_comment)`
- 字符串标识: `bool(has_string)`
- 数字标识: `bool(has_number)`
- 操作符标识: `bool(has_operator)`

#### 复杂度特征 (3维)
- 括号复杂度: `min(bracket_complexity / 10.0, 1.0)`
- 词汇密度: `word_count / max(len(content), 1)`
- 字符多样性: `len(set(content)) / max(len(content), 1)`

#### AI模式特征 (5维)
- AI关键词: 检测'comprehensive', 'sophisticated', 'implementation'等
- 文档字符串: 检测'"""', "'''"等
- 类型注解: 检测'->', 'List[', 'Optional['等
- 日志记录: 检测'logger.', 'logging.'等
- 高级导入: 检测'from typing import', 'from abc import'等

#### 上下文特征 (3维)
- 首行标识: `bool(is_first_line)`
- 末行标识: `bool(is_last_line)`
- 中间段标识: `bool(is_middle_section)`

### 3. 文件级特征提取器 (FileFeatureExtractor)

**功能**: 提取整个文件的统计特征 (14维)

**特征类别**:

#### 基础统计 (5维)
- 文件大小: `min(file_size / 1000.0, 1.0)`
- 代码密度: `non_empty_lines / total_lines`
- 注释比例: `comment_lines / code_lines`
- 平均行长度: `min(avg_line_length / 80.0, 1.0)`
- 平均缩进: `min(avg_indent / 10.0, 1.0)`

#### 复杂度特征 (4维)
- 平均复杂度: `min(avg_complexity / 5.0, 1.0)`
- 函数数量: `min(function_count / 20.0, 1.0)`
- 类数量: `min(class_count / 10.0, 1.0)`
- 导入数量: `min(import_count / 20.0, 1.0)`

#### AI风格特征 (5维)
- 文档字符串数量: `min(docstring_count / 10.0, 1.0)`
- 类型注解数量: `min(type_annotation_count / 20.0, 1.0)`
- 日志记录数量: `min(logging_count / 10.0, 1.0)`
- 异常处理数量: `min(exception_count / 10.0, 1.0)`
- 高级模式数量: `min(advanced_pattern_count / 10.0, 1.0)`

### 4. 特征融合模块 (FeatureFusion)

**功能**: 融合行级特征和文件级特征

**架构**:
```python
class FeatureFusion(nn.Module):
    def __init__(self):
        self.line_projection = nn.Linear(19, 64)    # 行级特征投影
        self.file_projection = nn.Linear(14, 64)    # 文件级特征投影
        self.fusion_layer = nn.Sequential(
            nn.Linear(128, 128),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.LayerNorm(128)
        )
```

**处理流程**:
1. 行级特征 (19维) → 投影层 → 64维
2. 文件级特征 (14维) → 投影层 → 64维
3. 拼接融合 → 128维
4. 融合处理 → 128维输出

### 5. 行间关系建模 (InterLineRelationship)

**功能**: 建模代码行之间的上下文关系

**架构**:
```python
class InterLineRelationship(nn.Module):
    def __init__(self):
        self.position_embedding = nn.Embedding(1000, 64)  # 位置编码
        self.self_attention = nn.MultiheadAttention(
            embed_dim=192,  # 128 + 64
            num_heads=8,
            dropout=0.1,
            batch_first=True
        )
        self.output_projection = nn.Linear(192, 128)
```

**处理流程**:
1. 特征 (128维) + 位置编码 (64维) → 192维
2. 多头自注意力机制 → 上下文特征
3. 输出投影 → 128维

### 6. CodeBERT编码器

**功能**: 使用预训练CodeBERT模型编码代码语义

**模型**: microsoft/codebert-base
- 参数量: 125M
- 隐藏维度: 768
- 注意力头数: 12
- 层数: 12

**处理流程**:
1. 代码行 → CodeBERT tokenizer → token ids
2. CodeBERT编码 → 768维语义向量
3. 提取[CLS] token作为代码行表示
4. 投影层 → 128维

### 7. 最终特征融合

**功能**: 融合手工特征和CodeBERT特征

**架构**:
```python
self.final_fusion = nn.Sequential(
    nn.Linear(256, 256),  # 128 + 128
    nn.ReLU(),
    nn.Dropout(0.1),
    nn.LayerNorm(256)
)
```

### 8. 行分类器

**功能**: 预测每行代码的AI概率

**架构**:
```python
self.line_classifier = nn.Sequential(
    nn.Linear(256, 128),
    nn.ReLU(),
    nn.Dropout(0.1),
    nn.Linear(128, 64),
    nn.ReLU(),
    nn.Dropout(0.1),
    nn.Linear(64, 1),
    nn.Sigmoid()
)
```

**输出**: 0-1之间的AI概率值

### 9. 阈值过滤模块 (ThresholdFilter)

**功能**: 根据阈值将概率转换为二分类结果

**参数**:
- 默认阈值: 0.5
- 可动态调整

**处理**:
```python
is_ai = (probability > threshold)
```

### 10. 结果聚合模块 (ResultAggregator)

**功能**: 聚合检测结果并生成统计信息

**输出格式**:
```python
{
    "file_path": str,
    "success": bool,
    "lines": [
        {
            "line_number": int,
            "content": str,
            "ai_prob": float,
            "is_ai": bool
        }
    ],
    "summary": {
        "total_lines": int,
        "code_lines": int,
        "ai_lines": int,
        "ai_percentage": float,
        "average_ai_prob": float
    }
}
```

## 训练策略

### 优化器配置
- CodeBERT参数: AdamW, lr=2e-5
- 其他参数: AdamW, lr=2e-4
- 权重衰减: 0.01

### 损失函数
- 二分类交叉熵损失 (BCELoss)

### 训练技巧
- 梯度裁剪
- 学习率调度
- 早停机制
- 模型检查点保存

## 使用方法

### 命令行接口
```bash
# 检测单个文件
python enhanced_ai_detector.py --input file.py --output results.json

# 检测目录 (递归)
python enhanced_ai_detector.py --input src/ --recursive --threshold 0.7

# 训练模型
python train_enhanced_detector.py --data training_data.json --epochs 20

# 快速测试
python test_enhanced_system.py
```

### Python API
```python
from enhanced_ai_detector import EnhancedAIDetectionSystem

# 初始化系统
detector = EnhancedAIDetectionSystem(threshold=0.5)

# 检测文件
result = detector.detect_file("example.py")

# 批量检测
results = detector.detect_batch(["file1.py", "file2.py"])
```

## 性能特点

### 优势
1. **多层次特征融合**: 结合手工特征和深度特征
2. **上下文建模**: 考虑代码行间关系
3. **预训练模型**: 利用CodeBERT的语义理解能力
4. **可解释性**: 提供详细的特征分析
5. **高精度**: 多模态特征提升检测准确率

### 技术创新
1. **特征工程**: 19维行级特征 + 14维文件级特征
2. **注意力机制**: 自注意力建模行间关系
3. **多学习率**: 对不同模块使用不同学习率
4. **端到端训练**: 联合优化所有组件

## 扩展性

### 支持的扩展
1. **新语言支持**: 添加文件扩展名即可
2. **特征扩展**: 可添加新的特征维度
3. **模型替换**: 可替换为其他预训练模型
4. **阈值策略**: 支持动态阈值和多阈值

### 部署选项
1. **本地部署**: 直接运行Python脚本
2. **API服务**: 封装为REST API
3. **批量处理**: 支持大规模文件批处理
4. **云端部署**: 支持容器化部署

## 总结

增强版AI代码检测系统通过多层次特征融合和深度学习技术，实现了高精度的AI代码检测。系统架构完整、可扩展性强，能够满足各种代码分析需求。 