#!/usr/bin/env python3
"""
æ¨¡å—åŒ–AIæ£€æµ‹ç³»ç»Ÿæµ‹è¯•è„šæœ¬
éªŒè¯æ¯ä¸ªæ¨¡å—æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import tempfile
import json
from pathlib import Path

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_modules():
    """æµ‹è¯•æ‰€æœ‰æ¨¡å—"""
    print("ðŸš€ æµ‹è¯•æ¨¡å—åŒ–AIæ£€æµ‹ç³»ç»Ÿ")
    print("=" * 60)
    
    # æµ‹è¯•1: æ–‡ä»¶è§£æžå™¨
    print("ðŸ“„ æµ‹è¯•1: æ–‡ä»¶è§£æžå™¨")
    try:
        from modules.file_parser import FileParser
        parser = FileParser()
        
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_code = '''def hello():
    print("Hello World")
    return True
'''
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(test_code)
            test_file = f.name
        
        result = parser.parse_file(test_file)
        print(f"   âœ… æ–‡ä»¶è§£æžæˆåŠŸ: {len(result['lines'])} è¡Œ")
        os.unlink(test_file)
    except Exception as e:
        print(f"   âŒ æ–‡ä»¶è§£æžå¤±è´¥: {e}")
    
    # æµ‹è¯•2: ç‰¹å¾æå–
    print("ðŸ”§ æµ‹è¯•2: ç‰¹å¾æå–")
    try:
        from modules.feature_extraction import LineFeatureExtractor, FileFeatureExtractor
        line_extractor = LineFeatureExtractor()
        file_extractor = FileFeatureExtractor()
        
        # æ¨¡æ‹Ÿè¡Œä¿¡æ¯
        line_info = {
            'content': 'def calculate_sum(a: int, b: int) -> int:',
            'line_number': 1,
            'is_empty': False,
            'indent_level': 0
        }
        file_context = {'total_lines': 3}
        
        line_features = line_extractor.extract_features(line_info, file_context)
        print(f"   âœ… è¡Œçº§ç‰¹å¾æå–: {len(line_features)} ç»´")
        
        # æ¨¡æ‹Ÿæ–‡ä»¶ä¿¡æ¯
        file_info = {
            'lines': [
                {'content': 'def hello():', 'is_empty': False, 'indent_level': 0},
                {'content': '    return True', 'is_empty': False, 'indent_level': 4}
            ]
        }
        file_features = file_extractor.extract_features(file_info)
        print(f"   âœ… æ–‡ä»¶çº§ç‰¹å¾æå–: {len(file_features)} ç»´")
    except Exception as e:
        print(f"   âŒ ç‰¹å¾æå–å¤±è´¥: {e}")
    
    # æµ‹è¯•3: ç‰¹å¾èžåˆ
    print("ðŸ”— æµ‹è¯•3: ç‰¹å¾èžåˆ")
    try:
        from modules.feature_fusion import FeatureFusion
        import torch
        
        fusion = FeatureFusion(line_feature_dim=19, file_feature_dim=14, output_dim=128)
        
        line_features = torch.randn(5, 19)  # 5è¡Œï¼Œ19ç»´ç‰¹å¾
        file_features = torch.randn(5, 14)  # 5è¡Œï¼Œ14ç»´ç‰¹å¾
        
        fused = fusion(line_features, file_features)
        print(f"   âœ… ç‰¹å¾èžåˆæˆåŠŸ: {fused.shape}")
    except Exception as e:
        print(f"   âŒ ç‰¹å¾èžåˆå¤±è´¥: {e}")
    
    # æµ‹è¯•4: è¡Œé—´å…³ç³»å»ºæ¨¡
    print("ðŸ§  æµ‹è¯•4: è¡Œé—´å…³ç³»å»ºæ¨¡")
    try:
        from modules.inter_line_modeling import InterLineRelationship
        import torch
        
        inter_line = InterLineRelationship(feature_dim=128, hidden_dim=64)
        
        features = torch.randn(1, 5, 128)  # 1ä¸ªæ–‡ä»¶ï¼Œ5è¡Œï¼Œ128ç»´ç‰¹å¾
        positions = torch.tensor([[0, 1, 2, 3, 4]])  # è¡Œä½ç½®
        
        contextual = inter_line(features, positions)
        print(f"   âœ… è¡Œé—´å…³ç³»å»ºæ¨¡æˆåŠŸ: {contextual.shape}")
    except Exception as e:
        print(f"   âŒ è¡Œé—´å…³ç³»å»ºæ¨¡å¤±è´¥: {e}")
    
    # æµ‹è¯•5: CodeBERTç¼–ç ï¼ˆå¯èƒ½éœ€è¦ç½‘ç»œï¼‰
    print("ðŸ¤– æµ‹è¯•5: CodeBERTç¼–ç ")
    try:
        from modules.codebert_encoding import CodeBERTEncoder
        
        encoder = CodeBERTEncoder(output_dim=128)
        
        code_lines = [
            "def hello():",
            "    return True",
            "print('Hello')"
        ]
        
        embeddings = encoder.encode_lines(code_lines)
        print(f"   âœ… CodeBERTç¼–ç æˆåŠŸ: {embeddings.shape}")
    except Exception as e:
        print(f"   âš ï¸ CodeBERTç¼–ç è·³è¿‡: {e}")
    
    # æµ‹è¯•6: åˆ†ç±»å™¨
    print("ðŸŽ¯ æµ‹è¯•6: åˆ†ç±»å™¨")
    try:
        from modules.classification import LineClassifier
        import torch
        
        classifier = LineClassifier(input_dim=256, hidden_dims=[128, 64])
        
        features = torch.randn(5, 256)  # 5è¡Œï¼Œ256ç»´ç‰¹å¾
        probabilities = classifier(features)
        print(f"   âœ… åˆ†ç±»å™¨é¢„æµ‹æˆåŠŸ: {probabilities.shape}")
    except Exception as e:
        print(f"   âŒ åˆ†ç±»å™¨å¤±è´¥: {e}")
    
    # æµ‹è¯•7: é˜ˆå€¼è¿‡æ»¤
    print("âš–ï¸ æµ‹è¯•7: é˜ˆå€¼è¿‡æ»¤")
    try:
        from modules.threshold_filter import ThresholdFilter
        import numpy as np
        
        filter_module = ThresholdFilter(threshold=0.5)
        
        probabilities = np.array([0.2, 0.6, 0.8, 0.3, 0.9])
        predictions = filter_module.filter(probabilities)
        print(f"   âœ… é˜ˆå€¼è¿‡æ»¤æˆåŠŸ: {predictions}")
    except Exception as e:
        print(f"   âŒ é˜ˆå€¼è¿‡æ»¤å¤±è´¥: {e}")
    
    # æµ‹è¯•8: ç»“æžœèšåˆ
    print("ðŸ“‹ æµ‹è¯•8: ç»“æžœèšåˆ")
    try:
        from modules.result_aggregation import ResultAggregator
        
        aggregator = ResultAggregator()
        
        # æ¨¡æ‹Ÿæ–‡ä»¶ä¿¡æ¯
        file_info = {
            'filepath': 'test.py',
            'total_lines': 3,
            'lines': [
                {'line_number': 1, 'content': 'def hello():', 'is_empty': False},
                {'line_number': 2, 'content': '    return True', 'is_empty': False},
                {'line_number': 3, 'content': '', 'is_empty': True}
            ]
        }
        
        ai_probabilities = [0.3, 0.7, 0.0]
        ai_predictions = [False, True, False]
        
        result = aggregator.aggregate_file_results(file_info, ai_probabilities, ai_predictions)
        print(f"   âœ… ç»“æžœèšåˆæˆåŠŸ: AIæ¯”ä¾‹ {result['summary']['ai_percentage']}%")
    except Exception as e:
        print(f"   âŒ ç»“æžœèšåˆå¤±è´¥: {e}")
    
    # æµ‹è¯•9: è¾“å‡ºç³»ç»Ÿ
    print("ðŸ’¾ æµ‹è¯•9: è¾“å‡ºç³»ç»Ÿ")
    try:
        from modules.output_system import OutputSystem
        
        output_system = OutputSystem(output_dir="./test_output")
        
        # æ¨¡æ‹Ÿæ£€æµ‹ç»“æžœ
        test_data = {
            "results": [
                {
                    "file_path": "test.py",
                    "success": True,
                    "lines": [
                        {"line_number": 1, "content": "def hello():", "ai_prob": 0.3, "is_ai": False}
                    ],
                    "summary": {
                        "total_lines": 1,
                        "code_lines": 1,
                        "ai_lines": 0,
                        "ai_percentage": 0.0,
                        "average_ai_prob": 0.3
                    }
                }
            ],
            "statistics": {
                "total_files": 1,
                "successful_files": 1,
                "total_lines": 1,
                "total_code_lines": 1,
                "total_ai_lines": 0,
                "overall_ai_percentage": 0.0
            },
            "metadata": {
                "timestamp": "2024-01-01T00:00:00"
            }
        }
        
        json_file = output_system.output_json(test_data, "test_result.json")
        print(f"   âœ… JSONè¾“å‡ºæˆåŠŸ: {json_file}")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists(json_file):
            os.unlink(json_file)
        if os.path.exists("./test_output"):
            import shutil
            shutil.rmtree("./test_output")
    except Exception as e:
        print(f"   âŒ è¾“å‡ºç³»ç»Ÿå¤±è´¥: {e}")
    
    print("\nâœ¨ æ¨¡å—æµ‹è¯•å®Œæˆ!")


def test_integration():
    """æµ‹è¯•é›†æˆç³»ç»Ÿ"""
    print("\nðŸ”§ æµ‹è¯•é›†æˆç³»ç»Ÿ")
    print("-" * 40)
    
    try:
        # å¯¼å…¥æ¨¡å—åŒ–æ£€æµ‹å™¨
        from modular_ai_detector import ModularAIDetector
        
        # åˆ›å»ºæ£€æµ‹å™¨å®žä¾‹ï¼ˆä½¿ç”¨éšæœºæƒé‡ï¼‰
        detector = ModularAIDetector()
        
        # èŽ·å–æž¶æž„ä¿¡æ¯
        arch_info = detector.get_architecture_info()
        print("ðŸ“‹ æž¶æž„ä¿¡æ¯:")
        for i, step in enumerate(arch_info['architecture_flow'], 1):
            print(f"  {i}. {step}")
        
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_code = '''def calculate_fibonacci(n: int) -> int:
    """Calculate fibonacci number with comprehensive error handling."""
    if not isinstance(n, int):
        raise TypeError("Input must be an integer")
    
    if n < 0:
        raise ValueError("Input must be non-negative")
    
    if n <= 1:
        return n
    
    return calculate_fibonacci(n-1) + calculate_fibonacci(n-2)

def simple_add(a, b):
    return a + b
'''
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(test_code)
            test_file = f.name
        
        # æµ‹è¯•æ–‡ä»¶æ£€æµ‹
        print(f"\nðŸ” æµ‹è¯•æ–‡ä»¶æ£€æµ‹: {os.path.basename(test_file)}")
        result = detector.detect_file(test_file)
        
        if result['success']:
            summary = result['summary']
            print(f"   âœ… æ£€æµ‹æˆåŠŸ!")
            print(f"   ðŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
            print(f"      æ€»è¡Œæ•°: {summary['total_lines']}")
            print(f"      ä»£ç è¡Œæ•°: {summary['code_lines']}")
            print(f"      AIè¡Œæ•°: {summary['ai_lines']}")
            print(f"      AIæ¯”ä¾‹: {summary['ai_percentage']}%")
            print(f"      å¹³å‡AIæ¦‚çŽ‡: {summary['average_ai_prob']}")
            
            # æ˜¾ç¤ºéƒ¨åˆ†æ£€æµ‹ç»“æžœ
            print(f"   ðŸ“ éƒ¨åˆ†æ£€æµ‹ç»“æžœ:")
            for line in result['lines'][:5]:
                indicator = "ðŸ¤–" if line['is_ai'] else "ðŸ‘¤"
                print(f"      {indicator} è¡Œ{line['line_number']}: {line['ai_prob']:.3f} - {line['content'][:50]}...")
        else:
            print(f"   âŒ æ£€æµ‹å¤±è´¥: {result.get('error', 'Unknown error')}")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        os.unlink(test_file)
        
        print("   âœ… é›†æˆæµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"   âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_modules()
    test_integration() 